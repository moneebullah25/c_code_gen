<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Basic Introduction of Bigram character-level language model which is one of the first topics to learn when learning about language models.">

<title>c_code_gen - Bigram Language Model Character Level</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="c_code_gen - Bigram Language Model Character Level">
<meta property="og:description" content="Basic Introduction of Bigram character-level language model which is one of the first topics to learn when learning about language models.">
<meta property="og:image" content="https://moneebullah25.github.io/c_code_gen/00_bigram_files/figure-html/cell-9-output-1.png">
<meta property="og:site-name" content="c_code_gen">
<meta property="og:image:height" content="1275">
<meta property="og:image:width" content="1289">
<meta name="twitter:title" content="c_code_gen - Bigram Language Model Character Level">
<meta name="twitter:description" content="Basic Introduction of Bigram character-level language model which is one of the first topics to learn when learning about language models.">
<meta name="twitter:image" content="https://moneebullah25.github.io/c_code_gen/00_bigram_files/figure-html/cell-9-output-1.png">
<meta name="twitter:image-height" content="1275">
<meta name="twitter:image-width" content="1289">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">c_code_gen</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./bigram.html">Bigram Language Model Character Level</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">c_code_gen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bigram.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Bigram Language Model Character Level</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multilayer Perceptron</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Batch Normalization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wavenet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wavenet</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transformers</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nano_gpt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nano GPT</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./uml_diagrams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">UML Diagrams</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./huggingface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HuggingFace</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#bigram" id="toc-bigram" class="nav-link active" data-scroll-target="#bigram">Bigram</a>
  <ul class="collapse">
  <li><a href="#bigram-dictionary" id="toc-bigram-dictionary" class="nav-link" data-scroll-target="#bigram-dictionary">Bigram Dictionary</a></li>
  <li><a href="#bigram-2d-tensor" id="toc-bigram-2d-tensor" class="nav-link" data-scroll-target="#bigram-2d-tensor">Bigram 2D Tensor</a>
  <ul class="collapse">
  <li><a href="#fixing-zero-row-and-column-problem" id="toc-fixing-zero-row-and-column-problem" class="nav-link" data-scroll-target="#fixing-zero-row-and-column-problem">Fixing zero row and column problem</a></li>
  </ul></li>
  <li><a href="#sampling-from-the-model" id="toc-sampling-from-the-model" class="nav-link" data-scroll-target="#sampling-from-the-model">Sampling from the model</a>
  <ul class="collapse">
  <li><a href="#vectorization-of-probabilities" id="toc-vectorization-of-probabilities" class="nav-link" data-scroll-target="#vectorization-of-probabilities">Vectorization of Probabilities</a></li>
  </ul></li>
  <li><a href="#training-loss-negative-log-likelihood" id="toc-training-loss-negative-log-likelihood" class="nav-link" data-scroll-target="#training-loss-negative-log-likelihood">Training Loss (Negative Log Likelihood)</a></li>
  </ul></li>
  <li><a href="#mlp-approach" id="toc-mlp-approach" class="nav-link" data-scroll-target="#mlp-approach">MLP Approach</a>
  <ul class="collapse">
  <li><a href="#training-set-of-bigrams" id="toc-training-set-of-bigrams" class="nav-link" data-scroll-target="#training-set-of-bigrams">Training set of bigrams</a></li>
  <li><a href="#one-hot-encoding" id="toc-one-hot-encoding" class="nav-link" data-scroll-target="#one-hot-encoding">One-hot encoding</a></li>
  <li><a href="#define-the-network" id="toc-define-the-network" class="nav-link" data-scroll-target="#define-the-network">Define the network</a>
  <ul class="collapse">
  <li><a href="#one-ouptut-neuron-single-outputs-for-each-example" id="toc-one-ouptut-neuron-single-outputs-for-each-example" class="nav-link" data-scroll-target="#one-ouptut-neuron-single-outputs-for-each-example">One Ouptut Neuron Single outputs for each example</a></li>
  <li><a href="#output-neurons" id="toc-output-neurons" class="nav-link" data-scroll-target="#output-neurons">Output Neurons</a></li>
  </ul></li>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link" data-scroll-target="#gradient-descent">Gradient Descent</a></li>
  <li><a href="#combine-the-forward-and-backward-pass-into-a-single-function" id="toc-combine-the-forward-and-backward-pass-into-a-single-function" class="nav-link" data-scroll-target="#combine-the-forward-and-backward-pass-into-a-single-function">Combine the forward and backward pass into a single function</a></li>
  <li><a href="#sampling-from-the-model-1" id="toc-sampling-from-the-model-1" class="nav-link" data-scroll-target="#sampling-from-the-model-1">Sampling from the model</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/moneebullah25/c_code_gen/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Bigram Language Model Character Level</h1>
</div>

<div>
  <div class="description">
    Basic Introduction of Bigram character-level language model which is one of the first topics to learn when learning about language models.
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Reading the names from the <code>names.txt</code> which contains the names in lowercase, separated by new line. Dataset is downloaded from <code>https://raw.githubusercontent.com/karpathy/makemore/master/names.txt</code></p>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> <span class="bu">open</span>(<span class="st">"names.txt"</span>, <span class="st">"r"</span>).read().splitlines()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Exploring</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"first 10 words</span><span class="sc">{</span>words[:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"length of words: </span><span class="sc">{</span><span class="bu">len</span>(words)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"min word length </span><span class="sc">{</span><span class="bu">min</span>(<span class="bu">len</span>(w) <span class="cf">for</span> (w) <span class="kw">in</span> words)<span class="sc">}</span><span class="ss"> and max word length </span><span class="sc">{</span><span class="bu">max</span>(<span class="bu">len</span>(w) <span class="cf">for</span> (w) <span class="kw">in</span> words)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>first 10 words['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']
length of words: 32033
min word length 2 and max word length 15</code></pre>
</div>
</div>
<section id="bigram" class="level1">
<h1>Bigram</h1>
<p>Bigram works with <code>2</code> words/characters at a time.</p>
<p>It uses the <code>previous</code> word/charachter to predict the <code>next</code> word/character. It is a simple model but it is a good starting point to understand the problem.</p>
<section id="bigram-dictionary" class="level2">
<h2 class="anchored" data-anchor-id="bigram-dictionary">Bigram Dictionary</h2>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the Bigrams</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> {}</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w <span class="kw">in</span> words:</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add start and end tokens</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    chs <span class="op">=</span> [<span class="st">"&lt;S&gt;"</span>] <span class="op">+</span> <span class="bu">list</span>(w) <span class="op">+</span> [<span class="st">"&lt;E&gt;"</span>]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ch1, ch2 <span class="kw">in</span> <span class="bu">zip</span>(chs, chs[<span class="dv">1</span>:]):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        bigram <span class="op">=</span> (ch1, ch2)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(bigram)</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># use get instead of b[bigram] to avoid KeyError and set default to 0</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        b[bigram] <span class="op">=</span> b.get(bigram, <span class="dv">0</span>) <span class="op">+</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We initially used <code>&lt;S&gt;</code> and <code>&lt;E&gt;</code> as the start and end token respectively. But this approach is not useful enough because we can’t have a character that starts before <code>&lt;S&gt;</code> so in the N lookup table there will be a complete row which have 0’s in it.</p>
<p>However instead of using <code>&lt;S&gt;</code> and <code>&lt;E&gt;</code>, we later substitue it for a single <code>.</code> character which indicates both the start and the end and make slight improvement in our code.</p>
<div class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print the most common bigrams in the data (sort by value)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">sorted</span>(b.items(), key <span class="op">=</span> <span class="kw">lambda</span> kv: kv[<span class="dv">1</span>], reverse <span class="op">=</span> <span class="va">True</span>)[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>[(('n', '&lt;E&gt;'), 6763),
 (('a', '&lt;E&gt;'), 6640),
 (('a', 'n'), 5438),
 (('&lt;S&gt;', 'a'), 4410),
 (('e', '&lt;E&gt;'), 3983),
 (('a', 'r'), 3264),
 (('e', 'l'), 3248),
 (('r', 'i'), 3033),
 (('n', 'a'), 2977),
 (('&lt;S&gt;', 'k'), 2963)]</code></pre>
</div>
</div>
</section>
<section id="bigram-2d-tensor" class="level2">
<h2 class="anchored" data-anchor-id="bigram-2d-tensor">Bigram 2D Tensor</h2>
<p>We are declaring a tensor which we will use to store the counts of our bigrams</p>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> torch.zeros(<span class="dv">28</span>, <span class="dv">28</span>, dtype <span class="op">=</span> torch.int32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can’t pass string data to our model we need to convert the characters to the number. Why characters? because it is a character level language model <code>Bigram</code> which means we will feed one character to our model and it will try to predict the next character in a sequence. We can also pass multiple character to our model but this is not the architecture of <code>Bigram</code>.</p>
<div class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make a list of characters (a -&gt; z)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(<span class="st">""</span>.join(words))))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># make a dictionary of character to index</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>stoi <span class="op">=</span> {ch: i <span class="cf">for</span> (i, ch) <span class="kw">in</span> <span class="bu">enumerate</span>(chars)}  <span class="co"># alphabet as key, integer as value</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>stoi[<span class="st">"&lt;S&gt;"</span>] <span class="op">=</span> <span class="bu">len</span>(chars)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>stoi[<span class="st">"&lt;E&gt;"</span>] <span class="op">=</span> <span class="bu">len</span>(chars) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># make a dictionary of index to character</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>itos <span class="op">=</span> {i: ch <span class="cf">for</span> (ch, i) <span class="kw">in</span> stoi.items()} <span class="co"># integer as key, alphabet as value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sample Bigram Language Model – Now basically A bigram language model is a type of language model that predicts the probability of a word in a sequence based on the previous word. Same is true for the character.</p>
<p>In the word case our vocabulary can be 17000 words or 100000 words based on the size of the problem, which in this case each word is assigned a index to be feed in to the model. But in the character level language model our vocabulary size is total number of character used in our whole dataset which are in this case 26 characters and we append <code>.</code> at the start and end of each name so total of we have 27 characters in our problem so our vocabulary size is 27 characters.</p>
<div class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the Bigrams</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w <span class="kw">in</span> words:</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add start and end tokens</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    chs <span class="op">=</span> [<span class="st">"&lt;S&gt;"</span>] <span class="op">+</span> <span class="bu">list</span>(w) <span class="op">+</span> [<span class="st">"&lt;E&gt;"</span>]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ch1, ch2 <span class="kw">in</span> <span class="bu">zip</span>(chs, chs[<span class="dv">1</span>:]):</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        ix1 <span class="op">=</span> stoi[ch1]</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        ix2 <span class="op">=</span> stoi[ch2]</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        N[ix1, ix2] <span class="op">+=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plotting Counts</p>
<div class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize this matrix</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">16</span>, <span class="dv">16</span>))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(N, cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># character strings</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        chstr <span class="op">=</span> itos[i] <span class="op">+</span> itos[j]</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, chstr, ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"bottom"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># bigram counts (.item() converts tensor to int)</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, N[i, j].item(), ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"top"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="fixing-zero-row-and-column-problem" class="level3">
<h3 class="anchored" data-anchor-id="fixing-zero-row-and-column-problem">Fixing zero row and column problem</h3>
<p>Notice we have empty <code>row</code> and <code>column</code> for <code>&lt;E&gt;</code> and <code>&lt;S&gt;</code> tokens respectively</p>
<p>We will solve that by replacing both of them with <code>.</code> token as follows:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make a list of characters (a -&gt; z)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(<span class="st">""</span>.join(words))))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># make a dictionary of character to index</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>stoi <span class="op">=</span> {ch: i <span class="cf">for</span> (i, ch) <span class="kw">in</span> <span class="bu">enumerate</span>(chars)}</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># remove theses tokens from the dictionary</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strike></strike></p><strike>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>stoi[<span class="st">"&lt;S&gt;"</span>] <span class="op">=</span> <span class="bu">len</span>(chars)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>stoi[<span class="st">"&lt;E&gt;"</span>] <span class="op">=</span> <span class="bu">len</span>(chars) <span class="op">+</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</strike><p><strike></strike></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># and add this token</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>stoi[<span class="st">"."</span>] <span class="op">=</span> <span class="bu">len</span>(chars)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># make a dictionary of index to character</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>itos <span class="op">=</span> {i: ch <span class="cf">for</span> (ch, i) <span class="kw">in</span> stoi.items()}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This time we are taking <code>27</code> characters because we are using <code>.</code> character at the start and at the end of each name</p>
<div class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> torch.zeros(<span class="dv">27</span>, <span class="dv">27</span>, dtype <span class="op">=</span> torch.int32)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make a list of characters (a -&gt; z)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(<span class="st">""</span>.join(words))))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># make a dictionary of character to index</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>stoi <span class="op">=</span> {ch: i <span class="op">+</span> <span class="dv">1</span> <span class="cf">for</span> (i, ch) <span class="kw">in</span> <span class="bu">enumerate</span>(chars)}  <span class="co"># alphabet as key, integer as value</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  set start and end tokens to 0</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>stoi[<span class="st">"."</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># make a dictionary of index to character</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>itos <span class="op">=</span> {i: ch <span class="cf">for</span> (ch, i) <span class="kw">in</span> stoi.items()} <span class="co"># integer as key, alphabet as value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the below code we are counting out of total <code>27*27</code> pairs of bigrams, how many times each bigram appeared in our names dataset. Also note than we append <code>.</code> character at the start and at the end of each name.</p>
<div class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the Bigrams</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w <span class="kw">in</span> words:</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add start and end tokens</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    chs <span class="op">=</span> [<span class="st">"."</span>] <span class="op">+</span> <span class="bu">list</span>(w) <span class="op">+</span> [<span class="st">"."</span>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ch1, ch2 <span class="kw">in</span> <span class="bu">zip</span>(chs, chs[<span class="dv">1</span>:]):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        ix1 <span class="op">=</span> stoi[ch1]</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        ix2 <span class="op">=</span> stoi[ch2]</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        N[ix1, ix2] <span class="op">+=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Plotting the Counts</p>
<div class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize this matrix</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">16</span>, <span class="dv">16</span>))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(N, cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">27</span>):</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">27</span>):</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># character strings</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        chstr <span class="op">=</span> itos[i] <span class="op">+</span> itos[j]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, chstr, ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"bottom"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># bigram counts (.item() converts tensor to int)</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, N[i, j].item(), ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"top"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Notice: - <code>..</code> is <code>zero</code>, since we don’t have <code>empty</code> words - the first <code>row</code> is <code>start</code> words - the first <code>column</code> is <code>end</code> words</p>
</section>
</section>
<section id="sampling-from-the-model" class="level2">
<h2 class="anchored" data-anchor-id="sampling-from-the-model">Sampling from the model</h2>
<div class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># probability of the first character</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> N[<span class="dv">0</span>].<span class="bu">float</span>() <span class="op">/</span> N[<span class="dv">0</span>].<span class="bu">sum</span>()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,
        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,
        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])</code></pre>
</div>
</div>
<p>Probability that any of the <code>27 characters</code> can be the first character is <code>1</code></p>
<div class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>p.<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="111">
<pre><code>tensor(1.)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># probability </span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> N[<span class="dv">0</span>].<span class="bu">float</span>() <span class="op">/</span> N[<span class="dv">0</span>].<span class="bu">sum</span>()</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># generator is a seed for reproducibility</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">2147483647</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from the p distribution using the generator (I got different results from Andrej's idk why)</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>ix <span class="op">=</span> torch.multinomial(p, num_samples <span class="op">=</span> <span class="dv">1</span> , replacement <span class="op">=</span> <span class="va">True</span>, generator <span class="op">=</span> g).item()</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># convert index to character</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>itos[ix]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>'j'</code></pre>
</div>
</div>
<p>Using the <code>p</code> as probability distribution we will use it with <code>torch.multinomial</code> to draw samples from <code>p</code> based on the probability</p>
<p><code>torch.multinomial</code> Returns a tensor where each row contains <code>num_samples</code> indices sampled from the multinomial probability distribution located in the corresponding row of tensor <code>p</code>.</p>
<p>So for each row of the character we draw using <code>torch.multinomial</code> we then calculate probability distribution for that row in the loop which undermine our performance</p>
<p><code>torch.rand</code> Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)[0,1)</p>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">2147483647</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> []</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    ix <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> N[ix].<span class="bu">float</span>() <span class="op">/</span> N[ix].<span class="bu">sum</span>()</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.multinomial(p, num_samples <span class="op">=</span> <span class="dv">1</span> , replacement <span class="op">=</span> <span class="va">True</span>, generator <span class="op">=</span> g).item()</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        out.append(itos[ix])</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ix <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>.join(out))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>junide.
janasah.
p.
cony.
a.
nn.
kohin.
tolian.
juee.
ksahnaauranilevias.</code></pre>
</div>
</div>
<section id="vectorization-of-probabilities" class="level3">
<h3 class="anchored" data-anchor-id="vectorization-of-probabilities">Vectorization of Probabilities</h3>
<p>Instead of calculating the probability distribution <code>p</code> everytime</p>
<section id="broadcasting-example" class="level4">
<h4 class="anchored" data-anchor-id="broadcasting-example">Broadcasting Example</h4>
<p>Two tensors are “broadcastable” if the following rules hold:</p>
<ul>
<li>Each tensor has at least one dimension.</li>
<li>When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.</li>
</ul>
<hr>
<p>Same shapes are always broadcastable (i.e.&nbsp;the above rules always hold)x=torch.empty(5,7,3) y=torch.empty(5,7,3)</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.empty(<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">3</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.empty(<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p>x and y are not broadcastable, because x does not have at least 1 dimension</p>
<div class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.empty((<span class="dv">0</span>,))</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.empty(<span class="dv">2</span>,<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p>Can line up trailing dimensions - x and y are broadcastable. - 1st trailing dimension: both have size 1 - 2nd trailing dimension: y has size 1 - 3rd trailing dimension: x size == y size - 4th trailing dimension: y dimension doesn’t exist</p>
<div class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.empty(<span class="dv">5</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.empty(  <span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p>x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3</p>
<div class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.empty(<span class="dv">5</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>torch.empty(  <span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visual-example" class="level4">
<h4 class="anchored" data-anchor-id="visual-example">Visual Example</h4>
<div class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>], [<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>]])</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize this matrix</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>plt.imshow(x, cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># character strings</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        chstr <span class="op">=</span> x[i, j].item()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, chstr, ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"bottom"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        plt.xticks([])</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        plt.yticks([])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize this matrix</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>], [<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>]])</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> [</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    torch.cat([(x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)), (x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)).<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)], dim <span class="op">=</span> <span class="dv">1</span>), <span class="co"># normalize by column =&gt; incorrect [Wrong]</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    torch.cat([(x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">False</span>)), (x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">False</span>)).<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)], dim <span class="op">=</span> <span class="dv">1</span>), <span class="co"># normalize by column =&gt; incorrect [Wrong]</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    torch.cat([(x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)), (x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)).<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)], dim <span class="op">=</span> <span class="dv">1</span>), <span class="co"># normalize by row =&gt; correct (sum of each row == 1)[Right]</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    torch.cat([(x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">False</span>)), (x <span class="op">/</span> x.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">False</span>)).<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)], dim <span class="op">=</span> <span class="dv">1</span>) <span class="co"># normalize by column  =&gt; incorrect [Wrong]</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize this matrices</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    axes[n <span class="op">//</span> <span class="dv">2</span>, n <span class="op">%</span> <span class="dv">2</span>].imshow(xs[n], cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>            chstr <span class="op">=</span> xs[n][i, j].item()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> j <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>                axes[n <span class="op">//</span> <span class="dv">2</span>, n <span class="op">%</span> <span class="dv">2</span>].text(j, i <span class="op">-</span> <span class="fl">0.25</span>, <span class="ss">f"row sum</span><span class="ch">\n</span><span class="sc">{</span><span class="bu">round</span>(chstr, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">"</span>, ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"top"</span>, color <span class="op">=</span> <span class="st">"white"</span>)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>                axes[n <span class="op">//</span> <span class="dv">2</span>, n <span class="op">%</span> <span class="dv">2</span>].text(j, i, <span class="bu">round</span>(chstr, <span class="dv">3</span>), ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"bottom"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> n <span class="op">//</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> <span class="kw">not</span>(n <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>                axes[n <span class="op">//</span> <span class="dv">2</span>, n <span class="op">%</span> <span class="dv">2</span>].set_title(<span class="ss">f"dim = </span><span class="sc">{</span>n <span class="op">//</span> <span class="dv">2</span><span class="sc">}</span><span class="ss">, keepdim = </span><span class="sc">{</span><span class="kw">not</span> <span class="bu">bool</span>(n <span class="op">%</span> <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> (incorrect)"</span>)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>                axes[n <span class="op">//</span> <span class="dv">2</span>, n <span class="op">%</span> <span class="dv">2</span>].set_title(<span class="ss">f"dim = </span><span class="sc">{</span>n <span class="op">//</span> <span class="dv">2</span><span class="sc">}</span><span class="ss">, keepdim = </span><span class="sc">{</span><span class="kw">not</span> <span class="bu">bool</span>(n <span class="op">%</span> <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> (correct)"</span>)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>            <span class="co"># remove ticks</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>            axes[n <span class="op">//</span> <span class="dv">2</span>, n <span class="op">%</span> <span class="dv">2</span>].set_xticks([])</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>            axes[n <span class="op">//</span> <span class="dv">2</span>, n <span class="op">%</span> <span class="dv">2</span>].set_yticks([])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="vectorization" class="level4">
<h4 class="anchored" data-anchor-id="vectorization">Vectorization</h4>
<p>Wrong boradcasting Example:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> N.<span class="bu">float</span>() <span class="op">/</span> N.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Broadcasting:</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># N.sum(dim = 1) =&gt; (27) =&gt; (1, 27) it became a row vector [Wrong]</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># N.float() =&gt; (27, 27)</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># P =&gt; (27, 27)</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrong [Wrong] sum of each row != 1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> N.<span class="bu">float</span>() <span class="op">/</span> N.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Broadcasting:</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># N.sum(dim = 1, keepdim = True) =&gt; (27, 1)</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># N.float() =&gt; (27, 27)</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># P =&gt; (27, 27)</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Correct [Right] sum of each row == 1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize this probability matrix, it matches the bigram matrix</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">16</span>, <span class="dv">16</span>))</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(N, cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">27</span>):</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">27</span>):</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># character strings</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>        chstr <span class="op">=</span> itos[i] <span class="op">+</span> itos[j]</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, chstr, ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"bottom"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># bigram counts (.item() converts tensor to int)</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, <span class="bu">round</span>(P[i, j].item(),<span class="dv">3</span>), ha <span class="op">=</span> <span class="st">"center"</span>, va <span class="op">=</span> <span class="st">"top"</span>, color <span class="op">=</span> <span class="st">"black"</span>)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from P</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> []</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">2147483647</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> []</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    ix <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> P[ix]</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.multinomial(p, num_samples <span class="op">=</span> <span class="dv">1</span> , replacement <span class="op">=</span> <span class="va">True</span>, generator <span class="op">=</span> g).item()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>        out.append(itos[ix])</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ix <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    names.append(<span class="st">""</span>.join(out))</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['junide.', 'janasah.', 'p.', 'cony.', 'a.', 'nn.', 'kohin.', 'tolian.', 'juee.', 'ksahnaauranilevias.']</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="training-loss-negative-log-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="training-loss-negative-log-likelihood">Training Loss (Negative Log Likelihood)</h2>
<div class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># getting the Bigrams</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w <span class="kw">in</span> words[:<span class="dv">3</span>]:</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add start and end tokens</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    chs <span class="op">=</span> [<span class="st">"."</span>] <span class="op">+</span> <span class="bu">list</span>(w) <span class="op">+</span> [<span class="st">"."</span>]</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ch1, ch2 <span class="kw">in</span> <span class="bu">zip</span>(chs, chs[<span class="dv">1</span>:]):</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        ix1 <span class="op">=</span> stoi[ch1]</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>        ix2 <span class="op">=</span> stoi[ch2]</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># probability of each bigram</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># should be 1/27 = 0.037 for a uniform distribution i.e., random guessing</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> P[ix1, ix2]</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>ch1<span class="sc">}{</span>ch2<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>prob<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>.e -&gt; 0.0478
em -&gt; 0.0377
mm -&gt; 0.0253
ma -&gt; 0.3899
a. -&gt; 0.1960
.o -&gt; 0.0123
ol -&gt; 0.0780
li -&gt; 0.1777
iv -&gt; 0.0152
vi -&gt; 0.3541
ia -&gt; 0.1381
a. -&gt; 0.1960
.a -&gt; 0.1377
av -&gt; 0.0246
va -&gt; 0.2495
a. -&gt; 0.1960</code></pre>
</div>
</div>
<p>We need a single number to combine all of these probabilities and measure the quality of the model <code>Maximum Likelihood Estimation</code></p>
<p>So, the <code>product of all probabilities</code> == the <code>sum of log of all probabilities</code> should be as <code>high as possible</code></p>
<p>Now when calculating the log likelihood if any of our probability is <code>0</code> our loss will be very much high. So what we will do we will add a very small amount to our <code>N</code> model so that each biagram will atleast be contributing a little to the output</p>
<div class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for smoothing (to prevent zero probabilities = log(0) = -inf)</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> (N<span class="op">+</span><span class="dv">1</span>).<span class="bu">float</span>() <span class="op">/</span> N.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In language models, the negative log-likelihood (NLL) is commonly used as a loss function during training. The goal of a language model is to predict the probability distribution of the next word in a sequence given the context of preceding words.</p>
<p>The NLL measures the difference between the predicted probability distribution and the actual distribution of the next word. Minimizing the NLL during training encourages the model to assign higher probabilities to the correct words. Mathematically, maximizing the log-likelihood is equivalent to minimizing the negative log-likelihood.</p>
<div class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nll_loss(input_list, verbose <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    log_likelihood <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w <span class="kw">in</span> input_list:</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># add start and end tokens</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>        chs <span class="op">=</span> [<span class="st">"."</span>] <span class="op">+</span> <span class="bu">list</span>(w) <span class="op">+</span> [<span class="st">"."</span>]</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ch1, ch2 <span class="kw">in</span> <span class="bu">zip</span>(chs, chs[<span class="dv">1</span>:]):</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>            ix1 <span class="op">=</span> stoi[ch1]</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>            ix2 <span class="op">=</span> stoi[ch2]</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>            <span class="co"># probability of each bigram</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>            <span class="co"># should be 1/27 = 0.037 for a uniform distribution i.e., random guessing</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>            prob <span class="op">=</span> P[ix1, ix2]</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>            logprob <span class="op">=</span> torch.log(prob)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>            log_likelihood <span class="op">+=</span> logprob</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>            n <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># higher the log probability (closer to 0) is better</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose:</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>ch1<span class="sc">}{</span>ch2<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>prob<span class="sc">:.4f}</span><span class="ss"> </span><span class="sc">{</span>logprob<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># higher the log likelihood (closer to 0) is better</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"log Likelihood: </span><span class="sc">{</span>log_likelihood<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># but in loss function lower is better, so we negate it</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>    nll <span class="op">=</span> <span class="op">-</span>log_likelihood</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Negative log likelihood: </span><span class="sc">{</span>nll<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize it</span></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Normalized Negative log Likelihood: </span><span class="sc">{</span>(nll <span class="op">/</span> n)<span class="sc">}</span><span class="ss">"</span>) <span class="co"># we need to minimize this</span></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>nll_loss(words[:<span class="dv">5</span>], verbose <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>.e -&gt; 0.0478 -3.0402
em -&gt; 0.0377 -3.2780
mm -&gt; 0.0254 -3.6713
ma -&gt; 0.3901 -0.9414
a. -&gt; 0.1960 -1.6297
.o -&gt; 0.0123 -4.3956
ol -&gt; 0.0781 -2.5492
li -&gt; 0.1777 -1.7274
iv -&gt; 0.0153 -4.1830
vi -&gt; 0.3545 -1.0372
ia -&gt; 0.1382 -1.9792
a. -&gt; 0.1960 -1.6297
.a -&gt; 0.1377 -1.9827
av -&gt; 0.0246 -3.7033
va -&gt; 0.2499 -1.3867
a. -&gt; 0.1960 -1.6297
.i -&gt; 0.0185 -3.9910
is -&gt; 0.0744 -2.5983
sa -&gt; 0.1483 -1.9086
ab -&gt; 0.0160 -4.1355
be -&gt; 0.2480 -1.3943
el -&gt; 0.1591 -1.8383
ll -&gt; 0.0964 -2.3389
la -&gt; 0.1880 -1.6714
a. -&gt; 0.1960 -1.6297
.s -&gt; 0.0642 -2.7460
so -&gt; 0.0656 -2.7237
op -&gt; 0.0121 -4.4146
ph -&gt; 0.1998 -1.6104
hi -&gt; 0.0959 -2.3450
ia -&gt; 0.1382 -1.9792
a. -&gt; 0.1960 -1.6297
log Likelihood: -77.71862030029297
Negative log likelihood: 77.71862030029297
Normalized Negative log Likelihood: 2.4287068843841553</code></pre>
</div>
</div>
<div class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check the loss of the sample names</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>nll_loss(names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>log Likelihood: -256.8978576660156
Negative log likelihood: 256.8978576660156
Normalized Negative log Likelihood: 3.471592664718628</code></pre>
</div>
</div>
<p>for first training example: <code>.emma.</code>: the nll is <code>2.512</code></p>
<p>for the first 5 training exampless: the average nll is <code>2.429</code></p>
</section>
</section>
<section id="mlp-approach" class="level1">
<h1>MLP Approach</h1>
<section id="training-set-of-bigrams" class="level2">
<h2 class="anchored" data-anchor-id="training-set-of-bigrams">Training set of bigrams</h2>
<p>In the below code <code>ys</code> is basically the shifted version of the <code>xs</code>. Which means training set will contains the previous character and the next character in the name</p>
<div class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>xs , ys <span class="op">=</span> [], []</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w <span class="kw">in</span> words:</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add start and end tokens</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    chs <span class="op">=</span> [<span class="st">"."</span>] <span class="op">+</span> <span class="bu">list</span>(w) <span class="op">+</span> [<span class="st">"."</span>]</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ch1, ch2 <span class="kw">in</span> <span class="bu">zip</span>(chs, chs[<span class="dv">1</span>:]):</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>        ix1 <span class="op">=</span> stoi[ch1]</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>        ix2 <span class="op">=</span> stoi[ch2]</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>        xs.append(ix1)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>        ys.append(ix2)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to tensors</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> torch.tensor(xs)</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> torch.tensor(ys)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a><span class="co"># first word: 5 separate examples (.emma =&gt; emma.)</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xs[:<span class="dv">5</span>])</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ys[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([ 0,  5, 13, 13,  1])
tensor([ 5, 13, 13,  1,  0])</code></pre>
</div>
</div>
</section>
<section id="one-hot-encoding" class="level2">
<h2 class="anchored" data-anchor-id="one-hot-encoding">One-hot encoding</h2>
<p><code>xenc = F.one_hot(xs, num_classes=27).float()</code></p>
<ul>
<li><code>F.one_hot(xs, num_classes=27)</code> converts the input sequence <code>xs</code> into a one-hot encoded representation. Each element in <code>xs</code> is replaced by a one-hot vector with a length of 27 (assuming 27 classes or tokens).</li>
<li><code>.float()</code> converts the one-hot encoded tensor to floating-point format, which is often required for further operations.</li>
</ul>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># you have to cast to float for one_hot (doesn't accept dtype parameter)</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>xenc <span class="op">=</span> F.one_hot(xs, num_classes <span class="op">=</span> <span class="dv">27</span>).<span class="bu">float</span>()</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(xenc[:<span class="dv">5</span>], cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="128">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f724696a2d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-32-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="define-the-network" class="level2">
<h2 class="anchored" data-anchor-id="define-the-network">Define the network</h2>
<section id="one-ouptut-neuron-single-outputs-for-each-example" class="level3">
<h3 class="anchored" data-anchor-id="one-ouptut-neuron-single-outputs-for-each-example">One Ouptut Neuron Single outputs for each example</h3>
<p><code>xenc @ W</code> - <code>@</code> is the matrix multiplication operator. It calculates the dot product of the one-hot encoded input <code>xenc</code> and the weight matrix <code>W</code>. - <code>xenc @ W</code> represents the predicted log-counts for each class.</p>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> torch.randn((<span class="dv">27</span>,<span class="dv">1</span>))</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co"># apply matrix multiplication (dot product): (5, 27) @ (27, 1) = (5, 1)</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>xenc[:<span class="dv">5</span>] <span class="op">@</span> W</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="129">
<pre><code>tensor([[-0.3263],
        [-0.3286],
        [-0.7713],
        [-0.7713],
        [-1.6685]])</code></pre>
</div>
</div>
</section>
<section id="output-neurons" class="level3">
<h3 class="anchored" data-anchor-id="output-neurons">Output Neurons</h3>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> torch.randn((<span class="dv">27</span>,<span class="dv">27</span>), requires_grad <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># apply matrix multiplication (dot product): (5, 27) @ (27, 27) = (5, 27)</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>xenc[:<span class="dv">5</span>] <span class="op">@</span> W</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>plt.imshow(xenc[:<span class="dv">5</span>] <span class="op">@</span> W.detach().numpy(), cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="130">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f724d981310&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-34-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent">Gradient Descent</h2>
<div class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> torch.randn((<span class="dv">27</span>,<span class="dv">27</span>), requires_grad <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>counts = logits.exp()  # counts, equivalent to N</code> - <code>logits.exp()</code> exponentiates the predicted log-counts, converting them into counts. This step is common in models where the output is interpreted as log-probabilities.</p>
<p><code>probs = counts / counts.sum(1, keepdims=True)</code> - <code>counts.sum(1, keepdims=True)</code> computes the sum of counts along the second dimension, ensuring that the result has the same shape as <code>counts</code>. - <code>probs</code> is the probability distribution over the classes for the next character, obtained by normalizing the counts.</p>
<p><code>loss = -probs[torch.arange(5), ys[:5]].log().mean()</code> - The above equation computes the negative log-likelihood loss for the first five names in the dataset. It selects the log-probabilities corresponding to the true labels <code>ys</code> and computes their negative mean.</p>
<div class="cell" data-execution_count="132">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># forward pass</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="co"># log-counts</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> xenc <span class="op">@</span> W </span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co"># exp them =&gt; counts</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> logits.exp()</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="co"># convert them into probabilities</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> counts <span class="op">/</span> counts.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co"># # the previous 3 lines can be replaced by:</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co"># probs = F.softmax(logits, dim = 1)</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span> probs[torch.arange(<span class="dv">5</span>), ys[:<span class="dv">5</span>]].log().mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>loss.item()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="133">
<pre><code>3.5917840003967285</code></pre>
</div>
</div>
<ul>
<li><code>W.grad = None</code> initializes the gradient of the weight matrix to zero before computing the backward pass.</li>
<li><code>loss.backward()</code> computes the gradients of the loss with respect to the parameters using backpropagation.</li>
</ul>
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">-=</span> <span class="fl">0.1</span> <span class="op">*</span> W.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>This performs a gradient descent update. It subtracts a multiple of the gradient from the current weight values to update them.</li>
<li>The learning rate is represented by the value <code>-0.1</code>. The negative sign indicates that it’s a gradient descent step.</li>
</ul>
<div class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># backward pass</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co"># set gradients to zero</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>W.grad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co"># update weights</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    W <span class="op">-=</span> <span class="fl">0.1</span> <span class="op">*</span> W.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>xs[:<span class="dv">5</span>]<span class="op">=</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>ys[:<span class="dv">5</span>]<span class="op">=</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The effect of all gradients are positive (increasing the loss) except for the correct one is negative (decreasing the loss)</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>plt.imshow(W.grad.detach().numpy()[xs[:<span class="dv">5</span>]], cmap <span class="op">=</span> <span class="st">"Blues"</span>)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="dv">27</span>), itos, rotation <span class="op">=</span> <span class="dv">90</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>xs[:5]=tensor([ 0,  5, 13, 13,  1])
ys[:5]=tensor([ 5, 13, 13,  1,  0])</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="00_bigram_files/figure-html/cell-39-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="combine-the-forward-and-backward-pass-into-a-single-function" class="level2">
<h2 class="anchored" data-anchor-id="combine-the-forward-and-backward-pass-into-a-single-function">Combine the forward and backward pass into a single function</h2>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> torch.randn((<span class="dv">27</span>,<span class="dv">27</span>), requires_grad <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># forward pass</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>    xenc <span class="op">=</span> F.one_hot(xs, num_classes <span class="op">=</span> <span class="dv">27</span>).<span class="bu">float</span>()</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> xenc <span class="op">@</span> W</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    counts <span class="op">=</span> torch.exp(logits)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> counts <span class="op">/</span> counts.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loss</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span> probs[torch.arange(<span class="bu">len</span>(xs)), ys].log().mean()</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add regularization</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">+=</span> <span class="fl">0.1</span> <span class="op">*</span> W.<span class="bu">pow</span>(<span class="dv">2</span>).mean()</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> k <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># backward pass</span></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>    W.grad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># update weights</span></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a>        W <span class="op">-=</span> <span class="dv">50</span> <span class="op">*</span> W.grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0: 3.8628
10: 2.7460
20: 2.6501
30: 2.6189
40: 2.6046
50: 2.5972
60: 2.5930
70: 2.5906
80: 2.5891
90: 2.5882</code></pre>
</div>
</div>
<p>We are expecting loss similar to the training example (about 2.5)</p>
</section>
<section id="sampling-from-the-model-1" class="level2">
<h2 class="anchored" data-anchor-id="sampling-from-the-model-1">Sampling from the model</h2>
<p>Now to get sample from the model we start from the <code>0</code> as index which is <code>.</code> character and pass it to our model and use <code>torch.multinomial</code> to draw sample from the distribution calculated by the last layer of our nerual network model</p>
<div class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from P</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">2147483647</span>)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> []</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    ix <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># previosly we used P[ix]</span></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> P[ix]</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># now we use the softmax of the logits</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># xenc = F.one_hot(torch.tensor([ix]), num_classes = 27).float()</span></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># logits = xenc @ W</span></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># counts = torch.exp(logits)</span></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># p = counts / counts.sum(dim = 1, keepdim = True)</span></span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.multinomial(p, num_samples <span class="op">=</span> <span class="dv">1</span> , replacement <span class="op">=</span> <span class="va">True</span>, generator <span class="op">=</span> g).item()</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>        out.append(itos[ix])</span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ix <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>.join(out))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>junide.
janasah.
p.
cony.
a.
nn.
kohin.
tolian.
juee.
ksahnaauranilevias.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from MLP</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">2147483647</span>)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> []</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    ix <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># previosly we used P[ix]</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># p = P[ix]</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># now we use the softmax of the logits</span></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>        xenc <span class="op">=</span> F.one_hot(torch.tensor([ix]), num_classes <span class="op">=</span> <span class="dv">27</span>).<span class="bu">float</span>()</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> xenc <span class="op">@</span> W</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> torch.exp(logits)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> counts <span class="op">/</span> counts.<span class="bu">sum</span>(dim <span class="op">=</span> <span class="dv">1</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.multinomial(p, num_samples <span class="op">=</span> <span class="dv">1</span> , replacement <span class="op">=</span> <span class="va">True</span>, generator <span class="op">=</span> g).item()</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>        out.append(itos[ix])</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ix <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>.join(out))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>junide.
janaqah.
p.
cfay.
a.
nn.
kohin.
tolian.
jgee.
ksahnaauyanilevias.</code></pre>
</div>
</div>
<p>The results are <code>the same</code>, since we’re using the <code>same model</code> with the same loss</p>
<p><code>W</code> is the <code>log counts</code> (estimated before from the bigram model)</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from c_code_gen.transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c_code_gen\n",
    "\n",
    "> Leveraging GPT For embedded C Code Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install c_code_gen\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill me in please! Don't forget code examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 9])\n",
      "Target shape: torch.Size([2, 8])\n",
      "Device available: cuda\n",
      "Output shape: torch.Size([2, 7, 10])\n",
      "Output: tensor([[[ 0.4464, -0.5610, -0.7114,  0.9363,  0.6822, -1.5460, -0.5701,\n",
      "          -0.0960,  0.4808,  0.1313],\n",
      "         [-0.7031,  0.6683, -0.6762, -0.0794, -0.2506, -0.9622, -0.1848,\n",
      "          -0.7650, -0.2054, -0.5386],\n",
      "         [-0.0112,  0.4172, -0.1490, -1.0593,  0.2641, -0.8530, -0.3859,\n",
      "          -0.3926, -0.3144, -0.1417],\n",
      "         [ 0.4123,  0.3738,  0.6268,  0.8212,  1.1357, -1.1602, -0.0434,\n",
      "          -1.7120,  0.1721, -0.5142],\n",
      "         [-0.5740,  0.6748,  0.4170,  1.0975, -0.0173, -0.5885, -1.8482,\n",
      "           0.1379,  0.7698, -0.3862],\n",
      "         [ 0.6030, -0.1450, -0.4451,  1.1064,  0.1838, -1.0696, -0.4320,\n",
      "           0.0764,  0.5091, -0.2963],\n",
      "         [ 0.0264,  0.1590, -0.4393,  0.9079,  0.7149, -1.4549,  0.1765,\n",
      "           0.3150,  0.3267, -0.9601]],\n",
      "\n",
      "        [[ 0.5317, -0.5054, -0.6930,  0.9477,  0.7169, -1.3674, -0.5864,\n",
      "          -0.1622,  0.5145,  0.1502],\n",
      "         [-0.5181,  1.1593, -0.3028,  0.6865, -0.1220, -0.7017, -1.0549,\n",
      "          -0.4249, -0.0154, -0.7563],\n",
      "         [ 0.0823,  0.9191, -0.1109,  0.1114,  0.0602, -1.0653, -0.8787,\n",
      "           0.1198, -0.4894, -0.1040],\n",
      "         [ 0.1353,  0.4007,  0.1736,  0.0703,  1.2294, -1.2375, -0.2426,\n",
      "          -1.0955,  0.2159, -0.7532],\n",
      "         [ 0.1648,  0.3638, -0.1407, -0.5300,  0.3209, -0.3451, -1.0195,\n",
      "           0.1148,  0.8064,  0.1274],\n",
      "         [-0.6308,  0.8116, -0.6778,  0.9686,  0.0346, -0.8795, -0.4404,\n",
      "          -0.3469,  0.3887, -0.2115],\n",
      "         [ 0.1550,  0.5274, -0.3766,  0.5200, -0.2350, -1.2167, -0.4607,\n",
      "           0.2098, -0.1927, -0.5351]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(device)\n",
    "    trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n",
    "    src_pad_idx = 0 # index of the padding token in source vocabulary\n",
    "    trg_pad_idx = 0 # index of the padding token in target vocabulary\n",
    "    src_vocab_size = 10 # number of unique tokens in source vocabulary\n",
    "    trg_vocab_size = 10 # number of unique tokens in target vocabulary\n",
    "    \n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Target shape: {trg.shape}\")\n",
    "    print(f\"Device available: {device}\")\n",
    "    \n",
    "    model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(device)\n",
    "    out = model(x, trg[:, :-1])\n",
    "    print(f\"Output shape: {out.shape}\")\n",
    "    print(f\"Output: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
